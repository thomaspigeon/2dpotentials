{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b7e033d",
   "metadata": {},
   "source": [
    "# Illustrate committor active learning with AMS on the MB potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import  HTML\n",
    "# Jupyter display settings\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668bac5b",
   "metadata": {},
   "source": [
    "General imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ce166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d60c30",
   "metadata": {},
   "source": [
    "Imports for AMS and muller brown potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e096339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from potentials.MullerBrown import MullerBrown\n",
    "from simulations.AMSSimulation import AMSOverdampedLangevin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a52007",
   "metadata": {},
   "source": [
    "Import for committor learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7139a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from committor.neural_net_models import CommittorOneDecoder\n",
    "from committor.train_committor import TainCommittorOverdampedOneDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6f27ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(committor) ## In case you want to restart from here at a certain point\n",
    "del(committor_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e4eca",
   "metadata": {},
   "source": [
    "Define potential and neural net for committor approximation and the corresponding training object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f11808",
   "metadata": {},
   "outputs": [],
   "source": [
    "pot = MullerBrown()\n",
    "committor = CommittorOneDecoder([2, 20, 20, 1], [1, 2], 0, pot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643a3c8",
   "metadata": {},
   "source": [
    "Define temperature via $\\beta = \\left( k_\\mathrm{B} T \\right)^{-1}$, time step size and AMS simulation object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a47fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.05\n",
    "dt = 0.0001\n",
    "AMS_on_MB = AMSOverdampedLangevin(pot, xi=None, beta=beta, forward=True, dt=dt, threshold=10**(-8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c1e20",
   "metadata": {},
   "source": [
    "Run dynamics to sample intitial conditions in reactant and product metastable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conditions = 20\n",
    "n_rep = 20\n",
    "k_min = 1\n",
    "ini_traj_f, ini_conds_f, _, n_steps_f = AMS_on_MB.sample_initial_conditions(n_conditions=n_conditions, save_gauss=True)\n",
    "AMS_on_MB.set_forward(False)\n",
    "ini_traj_b, ini_conds_b, _, n_steps_b = AMS_on_MB.sample_initial_conditions(n_conditions=n_conditions, save_gauss=True)\n",
    "AMS_on_MB.set_forward(True)\n",
    "print(n_steps_b + n_steps_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a6c45",
   "metadata": {},
   "source": [
    "Define the first training dataset for the committor function based only on short trajectories for initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea172302",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "if N == 1:\n",
    "    dataset_f = np.concatenate((ini_traj_f[\"x_traj\"][:-1, :], ini_traj_f[\"gauss_traj\"][1:, :], ini_traj_f[\"x_traj\"][1:, :]), axis=1)\n",
    "else:\n",
    "    dataset_f = np.concatenate((ini_traj_f[\"x_traj\"][:-N, :], ini_traj_f[\"gauss_traj\"][1:-N+1, :], ini_traj_f[\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "for i in range(1, N):\n",
    "    if i + 1 == N:\n",
    "        dataset_f = np.concatenate((dataset_f, ini_traj_f[\"gauss_traj\"][1+i:, :], ini_traj_f[\"x_traj\"][1+i:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_f = np.concatenate((dataset_f, ini_traj_f[\"gauss_traj\"][1+i:-N+1+i, :], ini_traj_f[\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "if N == 1:\n",
    "    dataset_b = np.concatenate((ini_traj_b[\"x_traj\"][:-1, :], ini_traj_b[\"gauss_traj\"][1:, :], ini_traj_b[\"x_traj\"][1:, :]), axis=1)\n",
    "else:\n",
    "    dataset_b = np.concatenate((ini_traj_b[\"x_traj\"][:-N, :], ini_traj_b[\"gauss_traj\"][1:-N+1, :], ini_traj_b[\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "for i in range(1, N):\n",
    "    if i + 1 == N:\n",
    "        dataset_b = np.concatenate((dataset_b, ini_traj_b[\"gauss_traj\"][1+i:, :], ini_traj_b[\"x_traj\"][1+i:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_b = np.concatenate((dataset_b, ini_traj_b[\"gauss_traj\"][1+i:-N+1+i, :], ini_traj_b[\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "dataset = {\"any_distrib\" : np.append(dataset_f, dataset_b, axis=0), \"beta\" : beta, \"dt\" : dt}\n",
    "print(dataset[\"any_distrib\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0856c",
   "metadata": {},
   "source": [
    "   Define the committor training object, and prepare training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "committor_training = TainCommittorOverdampedOneDecoder(committor, pot, dataset)\n",
    "committor_training.train_test_split(train_size= 1 * 10**2)\n",
    "committor_training.split_training_dataset_K_folds(2)\n",
    "committor_training.set_train_val_data(0)\n",
    "committor_training.set_optimizer('Adam', 0.001)\n",
    "loss_params = {}\n",
    "loss_params[\"ito_loss_weight\"] = 1.0\n",
    "loss_params[\"pen_points_weight\"] = 0.0 * 10**0\n",
    "loss_params[\"n_wait\"] = 50\n",
    "\n",
    "committor_training.set_loss_weight(loss_params)\n",
    "batch_size = 10\n",
    "max_epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9ffca",
   "metadata": {},
   "source": [
    "Train the committor model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_dict = committor_training.train(batch_size, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a842a7",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_on_grid = committor_training.committor_model.xi_forward(pot.x2d).reshape([100, 100])\n",
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(24, 4)) \n",
    "# loss function evolution \n",
    "ax0.plot(loss_dict[\"train_loss\"][10:], label='train loss')\n",
    "ax0.plot(loss_dict[\"test_loss\"][10:], label='test loss')\n",
    "ax0.legend()\n",
    "# log committor plot \n",
    "pot.plot_potential_heat_map(ax1)\n",
    "ax1.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax1.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "contour1 = ax1.contour(pot.x_plot, pot.y_plot, np.log(xi_on_grid), 40, cmap='viridis')\n",
    "fig.colorbar(contour1, ax=ax1) \n",
    "ax1.set_title(\"log(committor) iso-levels\")\n",
    "# dataset distribution \n",
    "pot.plot_potential_heat_map(ax2)\n",
    "ax2.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax2.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "ax2.scatter(committor_training.train_data[:, 0], committor_training.train_data[:, 1], color='orange', s=1)\n",
    "# log 1- committor plot  \n",
    "pot.plot_potential_heat_map(ax3)\n",
    "ax3.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax3.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "contour3 = ax3.contour(pot.x_plot, pot.y_plot, np.log(1-xi_on_grid), 40, cmap='viridis')\n",
    "fig.colorbar(contour3, ax=ax3) \n",
    "ax3.set_title(\"log(1 - committor) iso-levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d723498",
   "metadata": {},
   "source": [
    "Run AMS forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bf8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMS_on_MB.set_xi(committor_training.committor_model.xi_forward)\n",
    "p_f, z_kills_f, replicas_f, total_md_steps_f = AMS_on_MB.ams_run(ini_conds_f, n_rep, k_min, return_all=True, save_gauss=True)\n",
    "AMS_on_MB.set_forward(False)\n",
    "AMS_on_MB.set_xi(committor_training.committor_model.xi_backward)\n",
    "p_b, z_kills_b, replicas_b, total_md_steps_b = AMS_on_MB.ams_run(ini_conds_b, n_rep, k_min, return_all=True, save_gauss=True)\n",
    "AMS_on_MB.set_forward(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5477b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_f)\n",
    "print(p_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3972370",
   "metadata": {},
   "source": [
    "Add the new sampled trajectories to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b831b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  N = 1 Do not change the N if you want to add to the existing dataset because the time lagg has to be constant within the dataset. \n",
    "if N == 1:\n",
    "    dataset_f = np.concatenate((replicas_f[0][\"x_traj\"][:-1, :], replicas_f[0][\"gauss_traj\"][1:, :], replicas_f[0][\"x_traj\"][1:, :]), axis=1)\n",
    "else:\n",
    "    dataset_f = np.concatenate((replicas_f[0][\"x_traj\"][:-N, :], replicas_f[0][\"gauss_traj\"][1:-N+1, :], replicas_f[0][\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "for i in range(1, N):\n",
    "    if i + 1 == N:\n",
    "        dataset_f = np.concatenate((dataset_f, replicas_f[0][\"gauss_traj\"][1+i:, :], replicas_f[0][\"x_traj\"][1+i:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_f = np.concatenate((dataset_f, replicas_f[0][\"gauss_traj\"][1+i:-N+1+i, :], replicas_f[0][\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "data = dataset_f.copy()\n",
    "for j in range(1, len(replicas_f)):\n",
    "    if N == 1:\n",
    "        dataset_f = np.concatenate((replicas_f[j][\"x_traj\"][:-1, :], replicas_f[j][\"gauss_traj\"][1:, :], replicas_f[j][\"x_traj\"][1:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_f = np.concatenate((replicas_f[j][\"x_traj\"][:-N, :], replicas_f[j][\"gauss_traj\"][1:-N+1, :], replicas_f[j][\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "    for i in range(1, N):\n",
    "        if i + 1 == N:\n",
    "            dataset_f = np.concatenate((dataset_f, replicas_f[j][\"gauss_traj\"][1+i:, :], replicas_f[j][\"x_traj\"][1+i:, :]), axis=1)\n",
    "        else:\n",
    "            dataset_f = np.concatenate((dataset_f, replicas_f[j][\"gauss_traj\"][1+i:-N+1+i, :], replicas_f[j][\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "    data = np.append(data, dataset_f, axis=0)\n",
    "for j in range(len(replicas_b)):    \n",
    "    if N == 1:\n",
    "        dataset_b = np.concatenate((replicas_b[j][\"x_traj\"][:-1, :], replicas_b[j][\"gauss_traj\"][1:, :], replicas_b[j][\"x_traj\"][1:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_b = np.concatenate((replicas_b[j][\"x_traj\"][:-N, :], replicas_b[j][\"gauss_traj\"][1:-N+1, :], replicas_b[j][\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "    for i in range(1, N):\n",
    "        if i + 1 == N:\n",
    "            dataset_b = np.concatenate((dataset_b, replicas_b[j][\"gauss_traj\"][1+i:, :], replicas_b[j][\"x_traj\"][1+i:, :]), axis=1)\n",
    "        else:\n",
    "            dataset_b = np.concatenate((dataset_b, replicas_b[j][\"gauss_traj\"][1+i:-N+1+i, :], replicas_b[j][\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "    data = np.append(data, dataset_f, axis=0)\n",
    "\n",
    "## But you can start a new dataset and erase the previous one by uncommenting the newt line and comment the following one\n",
    "#dataset[\"any_distrib\"] = data\n",
    "dataset[\"any_distrib\"] = np.append(dataset[\"any_distrib\"], data, axis=0)\n",
    "print(dataset[\"any_distrib\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a3a25",
   "metadata": {},
   "source": [
    "Re-set the training dataset and train again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877fb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "committor_training.set_dataset(dataset)\n",
    "committor_training.train_test_split(train_size=1 * 10**3)\n",
    "committor_training.split_training_dataset_K_folds(2)\n",
    "committor_training.set_train_val_data(0)\n",
    "committor_training.set_optimizer('Adam', 0.001)\n",
    "batch_size = 100\n",
    "max_epochs = 10000\n",
    "loss_dict = committor_training.train(batch_size, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b437daac",
   "metadata": {},
   "source": [
    "Plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5db53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_on_grid = committor_training.committor_model.xi_forward(pot.x2d).reshape([100, 100])\n",
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(24, 4)) \n",
    "# loss function evolution \n",
    "ax0.plot(loss_dict[\"train_loss\"][10:], label='train loss')\n",
    "ax0.plot(loss_dict[\"test_loss\"][10:], label='test loss')\n",
    "ax0.legend()\n",
    "# log committor plot \n",
    "pot.plot_potential_heat_map(ax1)\n",
    "ax1.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='pink', label='Minimum energy path')\n",
    "ax1.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='pink')\n",
    "contour1 = ax1.contour(pot.x_plot, pot.y_plot, np.log(xi_on_grid), 40, cmap='viridis')\n",
    "fig.colorbar(contour1, ax=ax1) \n",
    "ax1.set_title(\"log(committor) iso-levels\")\n",
    "# dataset distribution \n",
    "pot.plot_potential_heat_map(ax2)\n",
    "ax2.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='pink', label='Minimum energy path')\n",
    "ax2.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='pink')\n",
    "ax2.scatter(committor_training.train_data[:, 0], committor_training.train_data[:, 1], color='orange', s=0.5)\n",
    "# log 1- committor plot  \n",
    "pot.plot_potential_heat_map(ax3)\n",
    "ax3.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='pink', label='Minimum energy path')\n",
    "ax3.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='pink')\n",
    "contour3 = ax3.contour(pot.x_plot, pot.y_plot, np.log(1 - xi_on_grid), 40, cmap='viridis')\n",
    "fig.colorbar(contour3, ax=ax3) \n",
    "ax3.set_title(\"log(1 - committor) iso-levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea5b88",
   "metadata": {},
   "source": [
    "Test the quality with the reference from finite elements method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ee2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.loadtxt('mueller_pts.csv', delimiter=',', dtype=float)\n",
    "tri = np.loadtxt('mueller_tri.csv', delimiter=',', dtype=int)\n",
    "q = np.loadtxt('Mueller_comm.txt', dtype=float)\n",
    "from matplotlib.tri import Triangulation, TriFinder, LinearTriInterpolator\n",
    "triangulation = Triangulation(pts[:,0], pts[:,1], tri)\n",
    "interp = LinearTriInterpolator(triangulation, q, trifinder=triangulation.get_trifinder())\n",
    "\n",
    "ref_committor_x2d = interp._interpolate_multikeys(x=pot.x2d[:,0], y=pot.x2d[:,1], tri_index=None, return_keys=('z',))[0].data.reshape(pot.n_bins_x, pot.n_bins_y)\n",
    "committor_on_x2d = committor_training.committor_model.xi_forward(pot.x2d).reshape(pot.n_bins_x, pot.n_bins_y)\n",
    "\n",
    "fig, (ax1, ax0, ax2) = plt.subplots(1, 3, figsize=(18, 4)) \n",
    "pot.plot_potential_heat_map(ax1)\n",
    "ax1.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='orange', label='Minimum energy path')\n",
    "ax1.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='orange')\n",
    "contour1 = ax1.contour(pot.x_plot, pot.y_plot, ref_committor_x2d, np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]), cmap='Greys')\n",
    "contour2 = committor_training.plot_committor_iso_levels(ax1, np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]), set_lim=False)\n",
    "fig.colorbar(contour1, ax=ax1, label=\"reference isolevels\", location=\"left\") \n",
    "fig.colorbar(contour2, ax=ax1, label=\"approximate isolevels\", location=\"right\") \n",
    "\n",
    "pot.plot_potential_heat_map(ax2)\n",
    "ax2.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='orange', label='Minimum energy path')\n",
    "ax2.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='orange')\n",
    "contour = ax2.contour(pot.x_plot, pot.y_plot, ref_committor_x2d - committor_on_x2d, 100, cmap='viridis')\n",
    "fig.colorbar(contour, ax=ax2, label=\"Absolute error\") \n",
    "\n",
    "ref_committor_MEP1 = interp._interpolate_multikeys(x=pot.minimum_energy_paths[0][:, 0], y=pot.minimum_energy_paths[0][:, 1], tri_index=None, return_keys=('z',))[0]\n",
    "ref_committor_MEP2 = interp._interpolate_multikeys(x=pot.minimum_energy_paths[1][:, 0], y=pot.minimum_energy_paths[1][:, 1], tri_index=None, return_keys=('z',))[0]\n",
    "committor_on_MEP1 = committor_training.committor_model.xi_forward(pot.minimum_energy_paths[0])\n",
    "committor_on_MEP2 = committor_training.committor_model.xi_forward(pot.minimum_energy_paths[1])\n",
    "\n",
    "committor_on_MEP = np.append(committor_on_MEP1[:,0], np.flip(committor_on_MEP2[:,0]))\n",
    "ref_committor_MEP = np.append(ref_committor_MEP1, np.flip(ref_committor_MEP2))\n",
    "err_MEP = committor_on_MEP - ref_committor_MEP\n",
    "ax0.plot(committor_on_MEP, label=\"approx on MEP\")\n",
    "ax0.plot(ref_committor_MEP, label=\"ref on MEP\")\n",
    "#ax0.plot(err_MEP, label=\"error on MEP2\")\n",
    "ax0.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdabed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE on a sample of 1000 configurations distributed according ot the reactive trajectories measure. \n",
    "react = np.loadtxt('react_trajs_mullerbrown.txt')\n",
    "\n",
    "ref_committor_react = interp._interpolate_multikeys(x=react[:,0], y=react[:,1], tri_index=None, return_keys=('z',))[0]\n",
    "app_committor_react = committor_training.committor_model.xi_forward(react)[:, 0]\n",
    "RMSE = np.sqrt(np.mean((ref_committor_react - app_committor_react)**2))\n",
    "print(\"RMSE react = \", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e17085",
   "metadata": {},
   "source": [
    "Sample some new initial conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_conditions = 100\n",
    "n_rep = 100\n",
    "k_min = 1\n",
    "ini_traj_f, ini_conds_f, _, n_steps_f = AMS_on_MB.sample_initial_conditions(n_conditions=n_conditions, save_gauss=True)\n",
    "AMS_on_MB.set_forward(False)\n",
    "ini_traj_b, ini_conds_b, _, n_steps_b = AMS_on_MB.sample_initial_conditions(n_conditions=n_conditions, save_gauss=True)\n",
    "AMS_on_MB.set_forward(True)\n",
    "print(n_steps_b + n_steps_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692efbd",
   "metadata": {},
   "source": [
    "Add to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  N = 1 Do not change the N if you want to add to the dataset because the time lagg has to be constant within the dataset. \n",
    "if N == 1:\n",
    "    dataset_f = np.concatenate((ini_traj_f[\"x_traj\"][:-1, :], ini_traj_f[\"gauss_traj\"][1:, :], ini_traj_f[\"x_traj\"][1:, :]), axis=1)\n",
    "else:\n",
    "    dataset_f = np.concatenate((ini_traj_f[\"x_traj\"][:-N, :], ini_traj_f[\"gauss_traj\"][1:-N+1, :], ini_traj_f[\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "for i in range(1, N):\n",
    "    if i + 1 == N:\n",
    "        dataset_f = np.concatenate((dataset_f, ini_traj_f[\"gauss_traj\"][1+i:, :], ini_traj_f[\"x_traj\"][1+i:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_f = np.concatenate((dataset_f, ini_traj_f[\"gauss_traj\"][1+i:-N+1+i, :], ini_traj_f[\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "if N == 1:\n",
    "    dataset_b = np.concatenate((ini_traj_b[\"x_traj\"][:-1, :], ini_traj_b[\"gauss_traj\"][1:, :], ini_traj_b[\"x_traj\"][1:, :]), axis=1)\n",
    "else:\n",
    "    dataset_b = np.concatenate((ini_traj_b[\"x_traj\"][:-N, :], ini_traj_b[\"gauss_traj\"][1:-N+1, :], ini_traj_b[\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "for i in range(1, N):\n",
    "    if i + 1 == N:\n",
    "        dataset_b = np.concatenate((dataset_b, ini_traj_b[\"gauss_traj\"][1+i:, :], ini_traj_b[\"x_traj\"][1+i:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_b = np.concatenate((dataset_b, ini_traj_b[\"gauss_traj\"][1+i:-N+1+i, :], ini_traj_b[\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "## But you can start a new dataset and erase the previous one by uncommenting the newt line and comment the two following \n",
    "#dataset[\"any_distrib\"] = np.append(dataset_f, dataset_b, axis=0)\n",
    "dataset[\"any_distrib\"] = np.append(dataset[\"any_distrib\"], dataset_f, axis=0)\n",
    "dataset[\"any_distrib\"] = np.append(dataset[\"any_distrib\"], dataset_b, axis=0)\n",
    "print(dataset[\"any_distrib\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968c504",
   "metadata": {},
   "source": [
    "Run AMS again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597051c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMS_on_MB.set_xi(committor_training.committor_model.xi_forward)\n",
    "p_f, z_kills_f, replicas_f, total_md_steps_f = AMS_on_MB.ams_run(ini_conds_f, n_rep, k_min, return_all=True, save_gauss=True)\n",
    "AMS_on_MB.set_forward(False)\n",
    "AMS_on_MB.set_xi(committor_training.committor_model.xi_backward)\n",
    "p_b, z_kills_b, replicas_b, total_md_steps_b = AMS_on_MB.ams_run(ini_conds_b, n_rep, k_min, return_all=True, save_gauss=True)\n",
    "AMS_on_MB.set_forward(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_f)\n",
    "print(p_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5307609c",
   "metadata": {},
   "source": [
    "Add sampled trajectories data to dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc930fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 ## Do not change the N if you want to add to the existing dataset because the time lagg has to be constant within the dataset. \n",
    "if N == 1:\n",
    "    dataset_f = np.concatenate((replicas_f[0][\"x_traj\"][:-1, :], replicas_f[0][\"gauss_traj\"][1:, :], replicas_f[0][\"x_traj\"][1:, :]), axis=1)\n",
    "else:\n",
    "    dataset_f = np.concatenate((replicas_f[0][\"x_traj\"][:-N, :], replicas_f[0][\"gauss_traj\"][1:-N+1, :], replicas_f[0][\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "for i in range(1, N):\n",
    "    if i + 1 == N:\n",
    "        dataset_f = np.concatenate((dataset_f, replicas_f[0][\"gauss_traj\"][1+i:, :], replicas_f[0][\"x_traj\"][1+i:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_f = np.concatenate((dataset_f, replicas_f[0][\"gauss_traj\"][1+i:-N+1+i, :], replicas_f[0][\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "data = dataset_f.copy()\n",
    "for j in range(1, len(replicas_f)):\n",
    "    if N == 1:\n",
    "        dataset_f = np.concatenate((replicas_f[j][\"x_traj\"][:-1, :], replicas_f[j][\"gauss_traj\"][1:, :], replicas_f[j][\"x_traj\"][1:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_f = np.concatenate((replicas_f[j][\"x_traj\"][:-N, :], replicas_f[j][\"gauss_traj\"][1:-N+1, :], replicas_f[j][\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "    for i in range(1, N):\n",
    "        if i + 1 == N:\n",
    "            dataset_f = np.concatenate((dataset_f, replicas_f[j][\"gauss_traj\"][1+i:, :], replicas_f[j][\"x_traj\"][1+i:, :]), axis=1)\n",
    "        else:\n",
    "            dataset_f = np.concatenate((dataset_f, replicas_f[j][\"gauss_traj\"][1+i:-N+1+i, :], replicas_f[j][\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "    data = np.append(data, dataset_f, axis=0)\n",
    "for j in range(len(replicas_b)):    \n",
    "    if N == 1:\n",
    "        dataset_b = np.concatenate((replicas_b[j][\"x_traj\"][:-1, :], replicas_b[j][\"gauss_traj\"][1:, :], replicas_b[j][\"x_traj\"][1:, :]), axis=1)\n",
    "    else:\n",
    "        dataset_b = np.concatenate((replicas_b[j][\"x_traj\"][:-N, :], replicas_b[j][\"gauss_traj\"][1:-N+1, :], replicas_b[j][\"x_traj\"][1:-N+1, :]), axis=1)\n",
    "    for i in range(1, N):\n",
    "        if i + 1 == N:\n",
    "            dataset_b = np.concatenate((dataset_b, replicas_b[j][\"gauss_traj\"][1+i:, :], replicas_b[j][\"x_traj\"][1+i:, :]), axis=1)\n",
    "        else:\n",
    "            dataset_b = np.concatenate((dataset_b, replicas_b[j][\"gauss_traj\"][1+i:-N+1+i, :], replicas_b[j][\"x_traj\"][1+i:-N+1+i, :]), axis=1)\n",
    "    data = np.append(data, dataset_f, axis=0)\n",
    "\n",
    "## But you can start a new dataset and erase the previous one by uncommenting the newt line and comment the following one\n",
    "dataset[\"any_distrib\"] = data\n",
    "dataset[\"any_distrib\"] = np.append(dataset[\"any_distrib\"], data, axis=0)\n",
    "print(dataset[\"any_distrib\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db416c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(committor) ## In case you want to restart from here at a certain point\n",
    "del(committor_training)\n",
    "committor = CommittorOneDecoder([2, 5, 5, 1], [1, 2], 0, pot)\n",
    "committor_training = TainCommittorOverdampedOneDecoder(committor, pot, dataset)\n",
    "committor_training.set_optimizer('Adam', 0.001)\n",
    "loss_params = {}\n",
    "loss_params[\"ito_loss_weight\"] = 1.0\n",
    "loss_params[\"pen_points_weight\"] = 0.0 * 10**0\n",
    "loss_params[\"n_wait\"] = 50\n",
    "committor_training.set_loss_weight(loss_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f61cf0",
   "metadata": {},
   "source": [
    "Re-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bacb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "committor_training.set_dataset(dataset)\n",
    "committor_training.train_test_split(train_size=1 * 10**3)\n",
    "committor_training.split_training_dataset_K_folds(2)\n",
    "committor_training.set_train_val_data(0)\n",
    "committor_training.set_optimizer('Adam', 0.001)\n",
    "batch_size = 500\n",
    "max_epochs = 10000\n",
    "loss_dict = committor_training.train(batch_size, max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349d1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_on_grid = committor_training.committor_model.xi_forward(pot.x2d).reshape([100, 100])\n",
    "fig, (ax0, ax1, ax2, ax3) = plt.subplots(1, 4, figsize=(24, 4)) \n",
    "# loss function evolution \n",
    "ax0.plot(loss_dict[\"train_loss\"][:], label='train loss')\n",
    "ax0.plot(loss_dict[\"test_loss\"][:], label='test loss')\n",
    "ax0.legend()\n",
    "# log committor plot \n",
    "pot.plot_potential_heat_map(ax1)\n",
    "ax1.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax1.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "contour1 = ax1.contour(pot.x_plot, pot.y_plot, np.log(xi_on_grid), 40, cmap='viridis')\n",
    "fig.colorbar(contour1, ax=ax1) \n",
    "ax1.set_title(\"log(committor) iso-levels\")\n",
    "# dataset distribution \n",
    "pot.plot_potential_heat_map(ax2)\n",
    "ax2.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax2.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "ax2.scatter(committor_training.train_data[:, 0], committor_training.train_data[:, 1], color='orange', s=0.5)\n",
    "# log 1- committor plot  \n",
    "pot.plot_potential_heat_map(ax3)\n",
    "ax3.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax3.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "contour3 = ax3.contour(pot.x_plot, pot.y_plot, np.log(1-xi_on_grid), 40, cmap='viridis')\n",
    "fig.colorbar(contour3, ax=ax3) \n",
    "ax3.set_title(\"log(1 - committor) iso-levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d541f7a",
   "metadata": {},
   "source": [
    "Plot figures to compare to the finite element reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = np.loadtxt('mueller_pts.csv', delimiter=',', dtype=float)\n",
    "tri = np.loadtxt('mueller_tri.csv', delimiter=',', dtype=int)\n",
    "q = np.loadtxt('Mueller_comm.txt', dtype=float)\n",
    "from matplotlib.tri import Triangulation, TriFinder, LinearTriInterpolator\n",
    "triangulation = Triangulation(pts[:,0], pts[:,1], tri)\n",
    "interp = LinearTriInterpolator(triangulation, q, trifinder=triangulation.get_trifinder())\n",
    "\n",
    "ref_committor_x2d = interp._interpolate_multikeys(x=pot.x2d[:,0], y=pot.x2d[:,1], tri_index=None, return_keys=('z',))[0].data.reshape(pot.n_bins_x, pot.n_bins_y)\n",
    "committor_on_x2d = committor_training.committor_model.xi_forward(pot.x2d).reshape(pot.n_bins_x, pot.n_bins_y)\n",
    "\n",
    "fig, (ax1, ax0, ax2) = plt.subplots(1, 3, figsize=(18, 4)) \n",
    "pot.plot_potential_heat_map(ax1)\n",
    "ax1.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='orange', label='Minimum energy path')\n",
    "ax1.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='orange')\n",
    "contour1 = ax1.contour(pot.x_plot, pot.y_plot, ref_committor_x2d, np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]), cmap='Greys')\n",
    "contour2 = committor_training.plot_committor_iso_levels(ax1, np.array([0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]), set_lim=False)\n",
    "fig.colorbar(contour1, ax=ax1, label=\"reference isolevels\", location=\"left\") \n",
    "fig.colorbar(contour2, ax=ax1, label=\"approximate isolevels\", location=\"right\") \n",
    "\n",
    "pot.plot_potential_heat_map(ax2)\n",
    "ax2.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='orange', label='Minimum energy path')\n",
    "ax2.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='orange')\n",
    "contour = ax2.contour(pot.x_plot, pot.y_plot, ref_committor_x2d - committor_on_x2d, 100, cmap='viridis')\n",
    "fig.colorbar(contour, ax=ax2, label=\"Absolute error\") \n",
    "\n",
    "ref_committor_MEP1 = interp._interpolate_multikeys(x=pot.minimum_energy_paths[0][:, 0], y=pot.minimum_energy_paths[0][:, 1], tri_index=None, return_keys=('z',))[0]\n",
    "ref_committor_MEP2 = interp._interpolate_multikeys(x=pot.minimum_energy_paths[1][:, 0], y=pot.minimum_energy_paths[1][:, 1], tri_index=None, return_keys=('z',))[0]\n",
    "committor_on_MEP1 = committor_training.committor_model.xi_forward(pot.minimum_energy_paths[0])\n",
    "committor_on_MEP2 = committor_training.committor_model.xi_forward(pot.minimum_energy_paths[1])\n",
    "\n",
    "committor_on_MEP = np.append(committor_on_MEP1[:,0], np.flip(committor_on_MEP2[:,0]))\n",
    "ref_committor_MEP = np.append(ref_committor_MEP1, np.flip(ref_committor_MEP2))\n",
    "err_MEP = committor_on_MEP - ref_committor_MEP\n",
    "ax0.plot(committor_on_MEP, label=\"approx on MEP\")\n",
    "ax0.plot(ref_committor_MEP, label=\"ref on MEP\")\n",
    "#ax0.plot(err_MEP, label=\"error on MEP\")\n",
    "ax0.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760045cd",
   "metadata": {},
   "source": [
    "Compute root mean squarred error of with respect to finite elements method solution on 1000 points sampled from the reactive trajectories density measure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78659b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "react = np.loadtxt('react_trajs_mullerbrown.txt')\n",
    "\n",
    "ref_committor_react = interp._interpolate_multikeys(x=react[:,0], y=react[:,1], tri_index=None, return_keys=('z',))[0]\n",
    "app_committor_react = committor_training.committor_model.xi_forward(react)[:, 0]\n",
    "RMSE = np.sqrt(np.mean((ref_committor_react - app_committor_react)**2))\n",
    "print(\"RMSE react = \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980113cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7691f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9ef8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de5abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164829f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Box to save a sub-sample of reactive trajectories sampled by AMS\n",
    "size = 10000\n",
    "react_trajs = replicas_b[-n_rep][\"x_traj\"]\n",
    "for i in range(1, n_rep):\n",
    "    react_trajs = np.append(react_trajs, replicas_b[-i][\"x_traj\"], axis=0)\n",
    "for i in range(len(replicas_f)):\n",
    "    react_trajs = np.append(react_trajs, replicas_f[-i][\"x_traj\"], axis=0)    \n",
    "print(react_trajs.shape)\n",
    "\n",
    "indices = np.random.choice(len(react_trajs), size=size)\n",
    "react = react_trajs[indices][:, :2]\n",
    "\n",
    "fig, (ax0) = plt.subplots(1, 1, figsize=(6, 4)) \n",
    "pot.plot_potential_heat_map(ax0)\n",
    "ax0.plot(pot.minimum_energy_paths[0][:, 0], pot.minimum_energy_paths[0][:, 1], color='purple', label='Minimum energy path')\n",
    "ax0.plot(pot.minimum_energy_paths[1][:, 0], pot.minimum_energy_paths[1][:, 1], color='purple')\n",
    "ax0.scatter(react[:, 0], react[:, 1], color='orange', s=0.5)\n",
    "print(react.shape)\n",
    "#np.savetxt('mullerbrown_react_dens.txt', react)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a09b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
